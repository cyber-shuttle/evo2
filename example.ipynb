{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17440de8",
   "metadata": {},
   "source": [
    "## Zero-shot prediction of *BRCA1* variant effects with Evo 2\n",
    "\n",
    "The human *BRCA1* gene encodes for a protein that repairs damaged DNA ([Moynahan et al., 1999](https://www.cell.com/molecular-cell/fulltext/S1097-2765%2800%2980202-6)). Certain variants of this gene have been associated with an increased risk of breast and ovarian cancers ([Miki et al., 1994](https://www.science.org/doi/10.1126/science.7545954?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%20%200pubmed)). Using Evo 2, we can predict whether a particular single nucleotide variant (SNV) of the *BRCA1* gene is likely to be harmful to the protein's function, and thus potentially increase the risk of cancer for the patient with the genetic variant.\n",
    "\n",
    "We start by loading a dataset from [Findlay et al. (2018)](https://www.nature.com/articles/s41586-018-0461-z), which contains experimentally measured function scores of 3,893 *BRCA1* SNVs. These function scores reflect the extent by which the genetic variant has disrupted the protein's function, with lower scores indicating greater disruption. In this dataset, the SNVs are classified into three categories based on their function scores: `LOF` (loss-of-function), `INT` (intermediate), and `FUNC` (functional). We start by reading in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4436579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Loaded airavata_jupyter_magic (2.1.4.post4) \n",
      "(current runtime = local)\n",
      "\n",
      "  %authenticate                              -- Authenticate to access high-performance runtimes.\n",
      "  %request_runtime <rt> [args]               -- Request a runtime named <rt> with configuration <args>.\n",
      "                                                Call multiple times to request multiple runtimes.\n",
      "  %restart_runtime <rt>                      -- Restart runtime <rt> if it hangs. This will clear all variables.\n",
      "  %stop_runtime <rt>                         -- Stop runtime <rt> when no longer needed.\n",
      "  %wait_for_runtime <rt>                     -- Wait for runtime <rt> to be ready.\n",
      "  %switch_runtime <rt>                       -- Switch the active runtime to <rt>. All subsequent cells will run here.\n",
      "  %%run_on <rt>                              -- Force a cell to always execute on <rt>, regardless of the active runtime.\n",
      "  %stat_runtime <rt>                         -- Show the status of runtime <rt>.\n",
      "  %copy_data source=<r1:f1> target=<r2:f2>   -- Copy <f1> in <r1> to <f2> in <r2>.\n",
      "  %open_tunnels <tn> --forward=<ports>       -- Open a TCP tunnel on the runtime.\n",
      "  %close_tunnels <tn>                        -- Close a TCP tunnel opened on the runtime.\n",
      "  %run_subprocess <pn> --command=<cmd>\n",
      "                       --forward=<ports>     -- Start a subprocess on the runtime.\n",
      "  %kill_subprocess <pn>                      -- Kill a subprocess started on the runtime.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c422c8d4cf4015a06e3e2e5f8bc2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Authenticated.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Authenticated.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting runtime=hpc_gpu...\n",
      "[Phoenix:gpu-h100, 60 Minutes, 1 Node(s), 4 CPU(s), 1 GPU(s), 40000 MB RAM, 1024 MB VRAM]\n",
      "* modules=[]\n",
      "* libraries=['python=3.11', 'pip', 'cuda-nvcc', 'numpy', 'pytorch', 'matplotlib', 'pandas', 'seaborn', 'scikit-learn', 'tqdm', 'rich', 'openpyxl', 'biopython', 'huggingface_hub', 'pyyaml', 'gcc_linux-64', 'ninja']\n",
      "* pip=[]\n",
      "* mounts=[]\n",
      "Requested runtime=hpc_gpu\n",
      "Request successful: runtime=hpc_gpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0981de5b77a8418cb67d54c434f85db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local:/var/folders/_n/fcf6nx4j67gbbt4_8mjqxdc80000gn/T/connection_b3swgblw.json --> hpc_gpu:connection_b3swgblw.json... [200]\n",
      "started proc_name=hpc_gpu_kernel on rt=hpc_gpu. pid=1526228\n",
      "forwarding ports=[12460, 12461, 12462, 12463, 12464]\n",
      "hpc_gpu:12460 -> access via 18.118.140.230:10000\n",
      "hpc_gpu:12461 -> access via 18.118.140.230:10001\n",
      "hpc_gpu:12462 -> access via 18.118.140.230:10002\n",
      "hpc_gpu:12463 -> access via 18.118.140.230:10003\n",
      "hpc_gpu:12464 -> access via 18.118.140.230:10004\n",
      "started ipykernel tunnels for hpc_gpu at 18.118.140.230\n",
      "started ipykernel client for hpc_gpu\n",
      "Remote Jupyter kernel launched and connected for runtime=hpc_gpu.\n",
      "Switched to runtime=hpc_gpu.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"airavata-python-sdk[notebook]\"\n",
    "import airavata_jupyter_magic\n",
    "\n",
    "%authenticate\n",
    "%request_runtime hpc_gpu --file=cybershuttle.yml --walltime=60 --use=Phoenix:gpu-h100\n",
    "%wait_for_runtime hpc_gpu --live\n",
    "%switch_runtime hpc_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4771ed-613d-4b36-a746-b803ab75d75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_gpu...\n",
      "waiting for cell to finish on hpc_gpu...\n",
      "Fri Jun 13 14:46:21 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:23:00.0 Off |                    0 |\n",
      "| N/A   33C    P0            109W /  700W |       1MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "cell finished on hpc_gpu.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf78c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing cell on hpc_gpu...\n",
      "waiting for cell to finish on hpc_gpu...\n",
      "Collecting git+https://github.com/cyber-shuttle/evo2.git\n",
      "  Cloning https://github.com/cyber-shuttle/evo2.git to /dev/shm/cybershuttle/tmp/pip-req-build-wbv9gza4\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cyber-shuttle/evo2.git /dev/shm/cybershuttle/tmp/pip-req-build-wbv9gza4\n",
      "  Resolved https://github.com/cyber-shuttle/evo2.git to commit 15ae58bf408163e46467f4822696da271594f029\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: biopython in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from evo2==0.1.0) (1.85)\n",
      "Requirement already satisfied: huggingface_hub in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from evo2==0.1.0) (0.33.0)\n",
      "Collecting vtx (from evo2==0.1.0)\n",
      "  Using cached vtx-1.0.6.tar.gz (26.4 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from evo2==0.1.0) (2.3.0)\n",
      "Requirement already satisfied: torch in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from evo2==0.1.0) (2.7.0)\n",
      "Requirement already satisfied: tqdm in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from evo2==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from evo2==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: filelock in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from huggingface_hub->evo2==0.1.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from huggingface_hub->evo2==0.1.0) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from huggingface_hub->evo2==0.1.0) (1.1.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from huggingface_hub->evo2==0.1.0) (25.0)\n",
      "Requirement already satisfied: requests in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from huggingface_hub->evo2==0.1.0) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from huggingface_hub->evo2==0.1.0) (4.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from requests->huggingface_hub->evo2==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from requests->huggingface_hub->evo2==0.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from requests->huggingface_hub->evo2==0.1.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from requests->huggingface_hub->evo2==0.1.0) (2025.4.26)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from torch->evo2==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from torch->evo2==0.1.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from torch->evo2==0.1.0) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from sympy>=1.13.3->torch->evo2==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from jinja2->torch->evo2==0.1.0) (3.0.2)\n",
      "Collecting torch (from evo2==0.1.0)\n",
      "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting transformer_engine==1.13.0 (from transformer_engine[pytorch]==1.13.0->vtx->evo2==0.1.0)\n",
      "  Using cached transformer_engine-1.13.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting einops==0.8.0 (from vtx->evo2==0.1.0)\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: rich in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from vtx->evo2==0.1.0) (14.0.0)\n",
      "Collecting transformer_engine_cu12==1.13.0 (from transformer_engine==1.13.0->transformer_engine[pytorch]==1.13.0->vtx->evo2==0.1.0)\n",
      "  Using cached transformer_engine_cu12-1.13.0-py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pydantic (from transformer_engine_cu12==1.13.0->transformer_engine==1.13.0->transformer_engine[pytorch]==1.13.0->vtx->evo2==0.1.0)\n",
      "  Using cached pydantic-2.11.6-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: importlib-metadata>=1.0 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from transformer_engine_cu12==1.13.0->transformer_engine==1.13.0->transformer_engine[pytorch]==1.13.0->vtx->evo2==0.1.0) (8.7.0)\n",
      "Collecting transformer_engine_torch==1.13.0 (from transformer_engine[pytorch]==1.13.0->vtx->evo2==0.1.0)\n",
      "  Using cached transformer_engine_torch-1.13.0.tar.gz (121 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->evo2==0.1.0)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch->evo2==0.1.0)\n",
      "  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch->evo2==0.1.0)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from importlib-metadata>=1.0->transformer_engine_cu12==1.13.0->transformer_engine==1.13.0->transformer_engine[pytorch]==1.13.0->vtx->evo2==0.1.0) (3.23.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->transformer_engine_cu12==1.13.0->transformer_engine==1.13.0->transformer_engine[pytorch]==1.13.0->vtx->evo2==0.1.0)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic->transformer_engine_cu12==1.13.0->transformer_engine==1.13.0->transformer_engine[pytorch]==1.13.0->vtx->evo2==0.1.0)\n",
      "  Using cached pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic->transformer_engine_cu12==1.13.0->transformer_engine==1.13.0->transformer_engine[pytorch]==1.13.0->vtx->evo2==0.1.0)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from rich->vtx->evo2==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from rich->vtx->evo2==0.1.0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /dev/shm/cybershuttle/envs/5f68e682/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->vtx->evo2==0.1.0) (0.1.2)\n",
      "Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Using cached transformer_engine-1.13.0-py3-none-any.whl (459 kB)\n",
      "Using cached transformer_engine_cu12-1.13.0-py3-none-manylinux_2_28_x86_64.whl (125.2 MB)\n",
      "Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "Using cached pydantic-2.11.6-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: evo2, vtx, transformer_engine_torch\n",
      "  Building wheel for evo2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for evo2: filename=evo2-0.1.0-py3-none-any.whl size=28542 sha256=e8c5f817b58c86dde427ad4efe5ad4a838545af35437b0df12bb3911c5152385\n",
      "  Stored in directory: /dev/shm/cybershuttle/tmp/pip-ephem-wheel-cache-6lebiu5f/wheels/ca/2c/05/90393b347d6bdc11fadf421b7cedd463561537cc8d35d60532\n",
      "  Building wheel for vtx (pyproject.toml) ... \u001b[?25l/"
     ]
    }
   ],
   "source": [
    "!PATH=\"$(dirname $(find $CONDA_PREFIX -name cc1plus)):$PATH\" pip install git+https://github.com/cyber-shuttle/evo2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%copy_data source=local:notebooks/brca1/GRCh37.p13_chr17.fna.gz target=hpc_gpu:GRCh37.p13_chr17.fna.gz\n",
    "%copy_data source=local:notebooks/brca1/41586_2018_461_MOESM3_ESM.xlsx target=hpc_gpu:41586_2018_461_MOESM3_ESM.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "from Bio import SeqIO\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "brca1_df = pd.read_excel('41586_2018_461_MOESM3_ESM.xlsx', header=2)\n",
    "brca1_df = brca1_df[[\n",
    "    'chromosome', 'position (hg19)', 'reference', 'alt', 'function.score.mean', 'func.class',\n",
    "]]\n",
    "\n",
    "brca1_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0c7d5",
   "metadata": {},
   "source": [
    "We then group the `FUNC` and `INT` classes of SNVs together into a single category (`FUNC/INT`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7df7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "brca1_df.rename(columns={\n",
    "    'chromosome': 'chrom',\n",
    "    'position (hg19)': 'pos',\n",
    "    'reference': 'ref',\n",
    "    'alt': 'alt',\n",
    "    'function.score.mean': 'score',\n",
    "    'func.class': 'class',\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert to two-class system\n",
    "brca1_df['class'] = brca1_df['class'].replace(['FUNC', 'INT'], 'FUNC/INT')\n",
    "\n",
    "brca1_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6f10c",
   "metadata": {},
   "source": [
    "We build a function to parse the reference and variant sequences of a 8,192-bp window around the genomic position of each SNV, using the reference sequence of human chromosome 17 where *BRCA1* is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be1bb8e",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 8192\n",
    "\n",
    "# Read the reference genome sequence of chromosome 17\n",
    "with gzip.open('GRCh37.p13_chr17.fna.gz', \"rt\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        seq_chr17 = str(record.seq)\n",
    "        break\n",
    "\n",
    "def parse_sequences(pos, ref, alt):\n",
    "    \"\"\"\n",
    "    Parse reference and variant sequences from the reference genome sequence.\n",
    "    \"\"\"\n",
    "    p = pos - 1 # Convert to 0-indexed position\n",
    "    full_seq = seq_chr17\n",
    "\n",
    "    ref_seq_start = max(0, p - WINDOW_SIZE//2)\n",
    "    ref_seq_end = min(len(full_seq), p + WINDOW_SIZE//2)\n",
    "    ref_seq = seq_chr17[ref_seq_start:ref_seq_end]\n",
    "    snv_pos_in_ref = min(WINDOW_SIZE//2, p)\n",
    "    var_seq = ref_seq[:snv_pos_in_ref] + alt + ref_seq[snv_pos_in_ref+1:]\n",
    "\n",
    "    # Sanity checks\n",
    "    assert len(var_seq) == len(ref_seq)\n",
    "    assert ref_seq[snv_pos_in_ref] == ref\n",
    "    assert var_seq[snv_pos_in_ref] == alt\n",
    "\n",
    "    return ref_seq, var_seq\n",
    "\n",
    "# Parse sequences for the first variant\n",
    "row = brca1_df.iloc[0]\n",
    "ref_seq, var_seq = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "\n",
    "print(row)\n",
    "print('--')\n",
    "print(f'Reference, SNV 0: ...{ref_seq[4082:4112]}...')\n",
    "print(f'Variant, SNV 0:   ...{var_seq[4082:4112]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd3e9a-0b33-44c4-a95a-9be49ef61a76",
   "metadata": {},
   "source": [
    "Then, we load Evo 2 1B and score the likelihoods of the reference and variant sequences of each SNV. (Note: we use the smaller Evo 2 1B base model here as a quick demonstration, but we strongly recommend using the larger Evo 2 7B and 40B models for more accurate predictions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evo2.models import Evo2\n",
    "\n",
    "# Load model\n",
    "model = Evo2('evo2_1b_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135bffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mappings of unique reference sequences\n",
    "ref_seqs = []\n",
    "ref_seq_to_index = {}\n",
    "\n",
    "# Parse sequences and store indexes\n",
    "ref_seq_indexes = []\n",
    "var_seqs = []\n",
    "\n",
    "for _, row in brca1_df.iterrows():\n",
    "    ref_seq, var_seq = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "\n",
    "    # Get or create index for reference sequence\n",
    "    if ref_seq not in ref_seq_to_index:\n",
    "        ref_seq_to_index[ref_seq] = len(ref_seqs)\n",
    "        ref_seqs.append(ref_seq)\n",
    "    \n",
    "    ref_seq_indexes.append(ref_seq_to_index[ref_seq])\n",
    "    var_seqs.append(var_seq)\n",
    "\n",
    "ref_seq_indexes = np.array(ref_seq_indexes)\n",
    "\n",
    "print(f'Scoring likelihoods of {len(ref_seqs)} reference sequences with Evo 2...')\n",
    "ref_scores = model.score_sequences(ref_seqs)\n",
    "\n",
    "print(f'Scoring likelihoods of {len(var_seqs)} variant sequences with Evo 2...')\n",
    "var_scores = model.score_sequences(var_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf2de1e-17b1-4f0d-9004-1eb917ed83ac",
   "metadata": {},
   "source": [
    "We calculate the change in likelihoods for each variant relative to the likelihood of their respective wild-type sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d5859-87ed-49c9-8e3d-18629f073022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subtract score of corresponding reference sequences from scores of variant sequences\n",
    "delta_scores = np.array(var_scores) - np.array(ref_scores)[ref_seq_indexes]\n",
    "\n",
    "# Add delta scores to dataframe\n",
    "brca1_df[f'evo2_delta_score'] = delta_scores\n",
    "\n",
    "brca1_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aea762-ef7f-4687-88ca-56d9042e7a0d",
   "metadata": {},
   "source": [
    "This delta likelihood should be predictive of how disruptive the SNV is to the protein's function: the lower the delta, the more likely that the SNV is disruptive. We can show this by comparing the distributions of delta likelihoods for the two classes of SNVs (functional/intermediate vs loss-of-function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c27729e-927e-42ec-b311-1e3d901eb29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 2))\n",
    "\n",
    "# Plot stripplot of distributions\n",
    "p = sns.stripplot(\n",
    "    data=brca1_df,\n",
    "    x='evo2_delta_score',\n",
    "    y='class',\n",
    "    hue='class',\n",
    "    order=['FUNC/INT', 'LOF'],\n",
    "    palette=['#777777', 'C3'],\n",
    "    size=2,\n",
    "    jitter=0.3,\n",
    ")\n",
    "\n",
    "# Mark medians from each distribution\n",
    "sns.boxplot(showmeans=True,\n",
    "            meanline=True,\n",
    "            meanprops={'visible': False},\n",
    "            medianprops={'color': 'k', 'ls': '-', 'lw': 2},\n",
    "            whiskerprops={'visible': False},\n",
    "            zorder=10,\n",
    "            x=\"evo2_delta_score\",\n",
    "            y=\"class\",\n",
    "            data=brca1_df,\n",
    "            showfliers=False,\n",
    "            showbox=False,\n",
    "            showcaps=False,\n",
    "            ax=p)\n",
    "plt.xlabel('Delta likelihood score, Evo 2')\n",
    "plt.ylabel('BRCA1 SNV class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3974e39-6c50-4503-9bab-829b1ac1b14a",
   "metadata": {},
   "source": [
    "We can also calculate the area under the receiver operating characteristic curve (AUROC) of this zero-shot prediction method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6cc5e-9c98-4010-8210-b38f570e1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUROC of zero-shot predictions\n",
    "y_true = (brca1_df['class'] == 'LOF')\n",
    "auroc = roc_auc_score(y_true, -brca1_df['evo2_delta_score'])\n",
    "\n",
    "print(f'Zero-shot prediction AUROC: {auroc:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd58550",
   "metadata": {},
   "outputs": [],
   "source": [
    "%stop_runtime hpc_gpu"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
